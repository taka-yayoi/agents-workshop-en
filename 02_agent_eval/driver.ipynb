{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ed9821c-1abb-4f1e-9d83-8fca510d8ac0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Hands-on Lab: Building an Agent System with Databricks\n",
    "\n",
    "**Please use Serverless Compute for Environment Version 1.**\n",
    "\n",
    "## Part 2 - Agent Evaluation\n",
    "Now that we have created an agent, how do we evaluate its performance?\n",
    "In Part 2, we will focus on evaluation by creating a product support agent.\n",
    "This agent will use the RAG approach to leverage product documents and answer questions about the products.\n",
    "\n",
    "### 2.1 Define New Agent and Retriever Tools\n",
    "- [**agent.py**]($./agent.py): A sample agent is set up. First, review this file to understand its components.\n",
    "- **Vector Search**: A vector search endpoint has been created to search for documents related to specific products.\n",
    "- **Create Retriever Functions**: Define the properties of the retriever and package it so that it can be called from the LLM.\n",
    "\n",
    "### 2.2 Create Evaluation Dataset\n",
    "- A sample evaluation dataset is provided, but it is also possible to [generate synthetically](https://www.databricks.com/jp/blog/streamline-ai-agent-evaluation-with-new-synthetic-data-capabilities).\n",
    "\n",
    "### 2.3 Run MLflow.evaluate()\n",
    "- MLflow tests the agent's responses using the evaluation dataset.\n",
    "- The LLM judge scores the output and summarizes everything in an easy-to-read UI.\n",
    "\n",
    "### 2.4 Make Necessary Improvements and Re-evaluate\n",
    "- Get feedback from the evaluation results and change the retriever settings.\n",
    "- Re-evaluate to confirm improvements!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1a0de4c-53dc-4d54-a712-ee4746da6b01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq mlflow-skinny[databricks] langgraph==0.3.4 databricks-langchain databricks-agents uv\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ea933d0-f4fb-4e83-937a-ac702c5aa338",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c2114fe-c731-46c8-9981-a93b13c41183",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Agent Configuration via Environment Variables\n",
    "\n",
    "Set parameters for `agent.py` from environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a5add43-e153-42f7-b9ad-2f171004d703",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Get information about the current user using the workspace client\n",
    "w = WorkspaceClient()\n",
    "user_email = w.current_user.me().emails[0].value\n",
    "username = user_email.split('@')[0]\n",
    "username = re.sub(r'[^a-zA-Z0-9_]', '_', username) # Replace special characters with underscores\n",
    "\n",
    "# Specify schema\n",
    "user_schema_name = f\"agents_lab_{username}\" # Per-user schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9776c34d-3d73-469a-aba0-8e1f856cf540",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# LLM endpoint name\n",
    "os.environ[\"LLM_ENDPOINT_NAME\"] = \"databricks-claude-3-7-sonnet\"\n",
    "\n",
    "# UC function tools\n",
    "os.environ[\"UC_TOOL_NAMES\"] = f\"{catalog_name}.{user_schema_name}.*\"\n",
    "\n",
    "# Vector Search name\n",
    "os.environ[\"VS_NAME\"] = f\"{catalog_name}.{system_schema_name}.product_docs_index\"\n",
    "\n",
    "print(\"Environment variables set:\")\n",
    "print(f\"LLM_ENDPOINT_NAME: {os.environ.get('LLM_ENDPOINT_NAME')}\")\n",
    "print(f\"UC_TOOL_NAMES: {os.environ.get('UC_TOOL_NAMES')}\")\n",
    "print(f\"VS_NAME: {os.environ.get('VS_NAME')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f85bb60-b76b-460d-b8f0-9ef2cde300f1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Agent Quick Test for Functionality Check"
    }
   },
   "outputs": [],
   "source": [
    "from agent import AGENT\n",
    "\n",
    "AGENT.predict({\"messages\": [{\"role\": \"user\", \"content\": \"Please provide troubleshooting tips for the Soundwave X5 Pro headphones.\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b363cf7-1ad3-4c7c-a6ef-1a89160f96b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "AGENT.predict({\"messages\": [{\"role\": \"user\", \"content\": \"What is today's date?\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba3f1e9d-8e93-4ba5-882c-521592ae3f41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Visualize the agent's graph structure\n",
    "display(Image(AGENT.agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa253ec9-edf7-475f-b9a3-f43fd9873c0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Log `agent` as an MLflow Model\n",
    "Log the agent as code in the [agent]($./agent) notebook. For more details, refer to [MLflow - Models from Code](https://mlflow.org/docs/latest/models.html#models-from-code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70068664-e8b4-410a-a490-bd4c4d93c467",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Determine Databricks resources for automatic authentication passthrough at deployment\n",
    "import mlflow\n",
    "from agent import tools, LLM_ENDPOINT_NAME\n",
    "from databricks_langchain import VectorSearchRetrieverTool\n",
    "from mlflow.models.resources import DatabricksFunction, DatabricksServingEndpoint\n",
    "from unitycatalog.ai.langchain.toolkit import UnityCatalogTool\n",
    "\n",
    "resources = [DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME)]\n",
    "for tool in tools:\n",
    "    if isinstance(tool, VectorSearchRetrieverTool):\n",
    "        resources.extend(tool.resources)\n",
    "    elif isinstance(tool, UnityCatalogTool):\n",
    "        resources.append(DatabricksFunction(function_name=tool.uc_function_name))\n",
    "\n",
    "input_example = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What color options are available for the Aria Modern Bookshelf?\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        name=\"agent\",\n",
    "        python_model=\"agent.py\",\n",
    "        input_example=input_example,\n",
    "        resources=resources,\n",
    "        extra_pip_requirements=[\n",
    "            \"databricks-connect\"\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "149b6f04-665b-493f-b89b-61a0240992dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the model and create a prediction function\n",
    "logged_model_uri = f\"runs:/{logged_agent_info.run_id}/agent\"\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model_uri)\n",
    "\n",
    "def predict_wrapper(query):\n",
    "    # Format input for chat-style model\n",
    "    model_input = {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": query}]\n",
    "    }\n",
    "    response = loaded_model.predict(model_input)\n",
    "    \n",
    "    messages = response['messages']\n",
    "    return messages[-1]['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f814c70c-a129-4b70-9be1-f1e4122213d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Evaluate the Agent with [Agent Evaluation](https://docs.databricks.com/aws/ja/generative-ai/agent-evaluation)\n",
    "\n",
    "Edit the requests and expected responses in the evaluation dataset, run the evaluation iteratively, and track the calculated quality metrics using MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14ccc20b-7251-405d-887a-3f628d9f8bbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"request\": [\n",
    "        \"What color options are available for the Aria Modern Bookshelf?\",\n",
    "        \"How can I clean the Aurora Oak Coffee Table without damaging it?\",\n",
    "        \"How should I clean the BlendMaster Elite 4000 after use?\",\n",
    "        \"What color variations are available for the Flexi-Comfort Office Desk?\",\n",
    "        \"What sizes are available for the StormShield Pro Men's Waterproof Jacket?\"\n",
    "    ],\n",
    "    \"expected_facts\": [\n",
    "        [\n",
    "            \"The Aria Modern Bookshelf is available in natural oak finish.\",\n",
    "            \"The Aria Modern Bookshelf is available in black finish.\",\n",
    "            \"The Aria Modern Bookshelf is available in white finish.\"\n",
    "        ],\n",
    "        [\n",
    "            \"Wipe with a soft, slightly damp cloth.\",\n",
    "            \"Do not use abrasive cleaners.\"\n",
    "        ],\n",
    "        [\n",
    "            \"Rinse the jar of the BlendMaster Elite 4000.\",\n",
    "            \"Rinse with lukewarm water.\",\n",
    "            \"Clean after each use.\"\n",
    "        ],\n",
    "        [\n",
    "            \"The Flexi-Comfort Office Desk is available in 3 colors.\"\n",
    "        ],\n",
    "        [\n",
    "            \"The StormShield Pro Men's Waterproof Jacket is available in sizes S, M, L, XL, XXL.\"\n",
    "        ]\n",
    "    ]\n",
    "}\n",
    "\n",
    "eval_dataset = pd.DataFrame(data)\n",
    "display(eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce4b226a-df63-495a-ad8a-501d90020247",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Define the [scorer](https://docs.databricks.com/gcp/ja/mlflow3/genai/eval-monitor/custom-judge/meets-guidelines) as the LLM judge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1da4a408-6f2e-43da-9fad-b293aaadba23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.genai.scorers import Guidelines, Safety\n",
    "import mlflow.genai\n",
    "\n",
    "# Create evaluation dataset\n",
    "eval_data = []\n",
    "for request, facts in zip(data[\"request\"], data[\"expected_facts\"]):\n",
    "    eval_data.append({\n",
    "        \"inputs\": {\n",
    "            \"query\": request  # Match the function argument\n",
    "        },\n",
    "        \"expected_response\": \"\\n\".join(facts)\n",
    "    })\n",
    "\n",
    "# Define evaluation scorers\n",
    "# Guidelines for the LLM judge to evaluate responses\n",
    "\n",
    "# Define a custom scorer specialized for product information evaluation\n",
    "scorers = [\n",
    "    Guidelines(\n",
    "        guidelines=\"\"\"Responses must include all expected facts:\n",
    "        - List all colors and sizes if applicable (partial lists are not allowed)\n",
    "        - Provide exact specifications if applicable (e.g., '5 ATM'; vague expressions are not allowed)\n",
    "        - If asked about cleaning procedures, include all steps\n",
    "        If any fact is missing or incorrect, the response fails.\"\"\",\n",
    "        name=\"completeness_and_accuracy\",\n",
    "    ),\n",
    "    Guidelines(\n",
    "        guidelines=\"\"\"Responses must be clear and direct:\n",
    "        - Answer the question precisely\n",
    "        - List options in list format, steps in step format\n",
    "        - No marketing language or unnecessary background\n",
    "        - Be concise and complete.\"\"\",\n",
    "        name=\"relevance_and_structure\",\n",
    "    ),\n",
    "    Guidelines(\n",
    "        guidelines=\"\"\"Responses must not deviate from the topic:\n",
    "        - Only answer about the product asked\n",
    "        - Do not add fictional features or colors\n",
    "        - Do not include general advice\n",
    "        - Use the product name exactly as stated in the request.\"\"\",\n",
    "        name=\"product_specificity\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51068f89-bdb4-46af-9bfd-5c0f2f7ab54f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Run the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecd0336c-a598-469a-8d87-cc748fc3157c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Running evaluation...\")\n",
    "with mlflow.start_run():\n",
    "    results = mlflow.genai.evaluate(\n",
    "        data=eval_data,\n",
    "        predict_fn=predict_wrapper, \n",
    "        scorers=scorers\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c3ff588-1223-4e8b-b332-e395bf244d0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Return to the [agent.py]($./agent.py) file and modify the prompt to reduce marketing exaggerations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb24a329-d91d-457e-8e4e-079bed89a428",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        name=\"agent\",\n",
    "        python_model=\"agent.py\",\n",
    "        input_example=input_example,\n",
    "        resources=resources,\n",
    "        extra_pip_requirements=[\n",
    "            \"databricks-connect\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Load the model and create a prediction function\n",
    "logged_model_uri = f\"runs:/{logged_agent_info.run_id}/agent\"\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model_uri)\n",
    "\n",
    "def predict_wrapper(query):\n",
    "    # Format input for chat-style model\n",
    "    model_input = {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": query}]\n",
    "    }\n",
    "    response = loaded_model.predict(model_input)\n",
    "    \n",
    "    messages = response['messages']\n",
    "    return messages[-1]['content']\n",
    "  \n",
    "print(\"Running evaluation...\")\n",
    "with mlflow.start_run():\n",
    "    results = mlflow.genai.evaluate(\n",
    "        data=eval_data,\n",
    "        predict_fn=predict_wrapper, \n",
    "        scorers=scorers,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03208667-abbd-4b26-8af7-bf1c427fa0aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register the Model in Unity Catalog\n",
    "\n",
    "Update the following `catalog`, `schema`, and `model_name` to register the MLflow model in Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "117f7e33-29b7-439a-b9f4-a69826ec3790",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# Define catalog, schema, and model name for UC model\n",
    "model_name = \"product_agent\"\n",
    "UC_MODEL_NAME = f\"{catalog_name}.{user_schema_name}.{model_name}\"\n",
    "\n",
    "# Register the model in UC\n",
    "uc_registered_model_info = mlflow.register_model(model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22f60ab5-82ca-44bf-821c-d47d8a07c6cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Access the model version and check the agent's lineage in the **Dependencies** tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4137b28-eb70-4246-a414-212375344d6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# Get the Databricks host URL\n",
    "workspace_url = spark.conf.get('spark.databricks.workspaceUrl')\n",
    "\n",
    "# Create an HTML link to the created agent\n",
    "html_link = f'<a href=\"https://{workspace_url}/explore/data/models/{catalog_name}/{user_schema_name}/product_agent\" target=\"_blank\">View registered agent in Unity Catalog</a>'\n",
    "display(HTML(html_link))\n",
    "\n",
    "# Access the model version and check the agent's lineage in the **Dependencies** tab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd9d9f86-6210-452a-8902-0d3b0a731822",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Agent Deployment\n",
    "\n",
    "Set the environment variables used above and deploy the agent to a model serving endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b54b3961-6059-4ba1-a1b4-80e9aa2a570e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "\n",
    "# Define environment variables as a dictionary\n",
    "environment_vars = {\n",
    "    \"LLM_ENDPOINT_NAME\": os.environ[\"LLM_ENDPOINT_NAME\"],\n",
    "    \"UC_TOOL_NAMES\": os.environ[\"UC_TOOL_NAMES\"],\n",
    "    \"VS_NAME\": os.environ[\"VS_NAME\"],\n",
    "}\n",
    "\n",
    "# Deploy the model to the review app and model serving endpoint\n",
    "endpoint_info = agents.deploy(\n",
    "    UC_MODEL_NAME,\n",
    "    uc_registered_model_info.version,\n",
    "    tags={\"endpointSource\": \"Agent Lab\"},\n",
    "    environment_vars=environment_vars,\n",
    "    timeout=900,  # Extended to 15 minutes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "728713ee-c340-4831-b870-c55d46f9a205",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Run the following cell and access the displayed link. Once the endpoint is **Ready**, select **Use > Try in Playground** in the top right corner to test it in the Playground.\n",
    "\n",
    "Sample query: `What color variations are available for the Flexi-Comfort Office Desk?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "297ceb92-b149-4014-ae28-fb95c0b58559",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "serving_endpoint_url = f\"https://{workspace_url}/ml/endpoints/{endpoint_info.endpoint_name}\"\n",
    "html_endpoint_link = f'<a href=\"{serving_endpoint_url}\" target=\"_blank\">View Serving Endpoint</a>'\n",
    "display(HTML(html_endpoint_link))\n",
    "\n",
    "# Run the following cell and access the displayed link. Once the endpoint is **Ready**, select **Use > Try in Playground** in the top right corner to test it in the Playground."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "149fc924-cf0b-4097-8d41-54b3437481d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Delete the Serving Endpoint\n",
    "\n",
    "Since serving endpoints incur charges, delete the endpoint once the hands-on lab is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e45d1c0-f11d-4faf-8068-89e1fc11dca6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Delete agent deployment\n",
    "from databricks import agents\n",
    "\n",
    "agents.delete_deployment(\n",
    "    model_name=UC_MODEL_NAME,\n",
    "    model_version=uc_registered_model_info.version\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96510c6c-aaed-463b-9475-7b3d31652e0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Future Directions\n",
    "\n",
    "- Further [evaluation](https://docs.databricks.com/aws/ja/mlflow3/genai/getting-started/eval) and [monitoring](https://docs.databricks.com/aws/ja/mlflow3/genai/eval-monitor/) for improvements\n",
    "- Integration with [apps](https://docs.databricks.com/aws/ja/dev-tools/databricks-apps/get-started)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8374786319056394,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "driver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
