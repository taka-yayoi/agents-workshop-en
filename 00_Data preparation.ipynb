{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74f2645d-839c-4775-beec-6d5bfa4d284d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Preparation of Hands-on Data\n",
    "\n",
    "Can be executed with serverless compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56b6760f-a1c1-4de4-b6e7-4e35d2ba4b2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bef3689c-d08d-4528-9101-ae9018d74867",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17c71ec2-85db-42ed-96e3-c8d41da23c46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create catalog\n",
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {catalog_name}\")\n",
    "spark.sql(f\"GRANT USE CATALOG ON CATALOG {catalog_name} TO `account users`\")\n",
    "# Create schema\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog_name}.{system_schema_name}\")\n",
    "spark.sql(f\"GRANT USE SCHEMA, SELECT ON SCHEMA {catalog_name}.{system_schema_name} TO `account users`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7abc06cf-ecc6-4c7f-9718-b5295686221f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create volume\n",
    "spark.sql(f\"CREATE VOLUME IF NOT EXISTS {catalog_name}.{system_schema_name}.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bd9b9c9-b7d7-4368-9fd7-46fc1659ef95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Define volume path\n",
    "volume_path = f\"/Volumes/{catalog_name}/{system_schema_name}/data\"\n",
    "\n",
    "# Path to workspace files\n",
    "workspace_data_path = f\"{os.getcwd()}/data\"\n",
    "\n",
    "# Copy CSV files in the data folder to the volume\n",
    "for fname in [\"cust_service_data.csv\", \"policies.csv\", \"product_docs.csv\"]:\n",
    "    src = os.path.join(workspace_data_path, fname)\n",
    "    dst = os.path.join(volume_path, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# Load CSV files from the volume\n",
    "cust_service_data_df = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", True)\n",
    "    .option(\"inferSchema\", True)\n",
    "    .load(f\"{volume_path}/cust_service_data.csv\")\n",
    ")\n",
    "policies_df = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", True)\n",
    "    .option(\"inferSchema\", True)\n",
    "    .load(f\"{volume_path}/policies.csv\")\n",
    ")\n",
    "product_docs_df = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", True)\n",
    "    .option(\"inferSchema\", True)\n",
    "    .option(\"multiline\", True)\n",
    "    .load(f\"{volume_path}/product_docs.csv\")\n",
    ")\n",
    "\n",
    "display(cust_service_data_df)\n",
    "display(policies_df)\n",
    "display(product_docs_df)\n",
    "\n",
    "# Save to Unity Catalog tables\n",
    "cust_service_data_df.write.mode(\"overwrite\").saveAsTable(f\"{catalog_name}.{system_schema_name}.cust_service_data\")\n",
    "policies_df.write.mode(\"overwrite\").saveAsTable(f\"{catalog_name}.{system_schema_name}.policies\")\n",
    "product_docs_df.write.mode(\"overwrite\").saveAsTable(f\"{catalog_name}.{system_schema_name}.product_docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7f709d1-1fbf-4786-80b0-7454de8fc423",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create Vector Search Index\n",
    "\n",
    "Create the Vector Search Index to be used in `02_agent_eval`. Each user will use this Vector Search Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d692aad-1ecf-4fdd-ba6f-83986984e763",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Source table name\n",
    "source_table = f\"{catalog_name}.{system_schema_name}.product_docs\"\n",
    "\n",
    "# Enable Change Data Feed\n",
    "spark.sql(f\"\"\"\n",
    "    ALTER TABLE {source_table} \n",
    "    SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\n",
    "\"\"\")\n",
    "\n",
    "print(f\"‚úÖ Enabled Change Data Feed for {source_table}\")\n",
    "\n",
    "# Check settings\n",
    "spark.sql(f\"SHOW TBLPROPERTIES {source_table}\").filter(\"key = 'delta.enableChangeDataFeed'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3369a8a-6279-4280-b6c2-e4c3cce7bb14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "context = dbutils.notebook.entry_point.getDbutils().notebook().getContext()\n",
    "host = context.apiUrl().get()\n",
    "token = context.apiToken().get()\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {token}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Parameters\n",
    "endpoint_name = \"vector-search-endpoint-1\" # Change as needed\n",
    "index_name = f\"{catalog_name}.{system_schema_name}.product_docs_index\"\n",
    "source_table = f\"{catalog_name}.{system_schema_name}.product_docs\"\n",
    "\n",
    "# Check existence and create Vector Search Endpoint\n",
    "endpoint_url = f\"{host}/api/2.0/vector-search/endpoints/{endpoint_name}\"\n",
    "create_endpoint_url = f\"{host}/api/2.0/vector-search/endpoints\"\n",
    "\n",
    "response = requests.get(endpoint_url, headers=headers)\n",
    "if response.status_code == 200:\n",
    "    print(f\"‚úÖ Vector Search Endpoint '{endpoint_name}' already exists\")\n",
    "else:\n",
    "    print(f\"üîÑ Creating Vector Search Endpoint '{endpoint_name}' ...\")\n",
    "    payload = {\n",
    "        \"name\": endpoint_name,\n",
    "        \"endpoint_type\": \"STANDARD\"\n",
    "    }\n",
    "    create_response = requests.post(create_endpoint_url, headers=headers, json=payload)\n",
    "    if create_response.status_code in [200, 201]:\n",
    "        print(f\"‚úÖ Created Vector Search Endpoint '{endpoint_name}'!\")\n",
    "    elif create_response.status_code == 409:\n",
    "        print(f\"‚ö†Ô∏è  Vector Search Endpoint '{endpoint_name}' already exists (409)\")\n",
    "    else:\n",
    "        print(f\"‚ùå Endpoint creation error: {create_response.status_code}\")\n",
    "        print(create_response.text)\n",
    "\n",
    "# Create index\n",
    "url = f\"{host}/api/2.0/vector-search/indexes\"\n",
    "\n",
    "payload = {\n",
    "    \"name\": index_name,\n",
    "    \"endpoint_name\": endpoint_name,\n",
    "    \"primary_key\": \"product_id\",\n",
    "    \"index_type\": \"DELTA_SYNC\",\n",
    "    \"delta_sync_index_spec\": {\n",
    "        \"source_table\": source_table,\n",
    "        \"pipeline_type\": \"TRIGGERED\",\n",
    "        \"embedding_source_columns\": [{  # columns is an array\n",
    "            \"name\": \"product_doc\",\n",
    "            \"embedding_model_endpoint_name\": \"databricks-gte-large-en\"\n",
    "        }]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Creating Vector Search Index...\")\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "if response.status_code in [200, 201]:\n",
    "    print(\"‚úÖ Index creation request sent successfully!\")\n",
    "    print(\"üìä Initial sync will start automatically...\\n\")\n",
    "else:\n",
    "    print(f\"‚ùå Index creation error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7255c5ce-3bbe-4c91-911c-09b9503a775c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if response.status_code in [200, 201]:\n",
    "    \n",
    "    # Monitor index status\n",
    "    def monitor_index_status(index_name, timeout_minutes=60):\n",
    "        status_url = f\"{host}/api/2.0/vector-search/indexes/{index_name}\"\n",
    "        start_time = time.time()\n",
    "        timeout_seconds = timeout_minutes * 60\n",
    "        \n",
    "        print(f\"‚è≥ Monitoring index status...\")\n",
    "        print(f\"Timeout: {timeout_minutes} minutes\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        previous_count = 0\n",
    "        first_check = True\n",
    "        \n",
    "        while time.time() - start_time < timeout_seconds:\n",
    "            try:\n",
    "                response = requests.get(status_url, headers=headers)\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    status = data.get(\"status\", {})\n",
    "                    spec = data.get(\"delta_sync_index_spec\", {})\n",
    "                    \n",
    "                    # Status information\n",
    "                    state = status.get(\"detailed_state\", \"Unknown\")\n",
    "                    ready = status.get(\"ready\", False)\n",
    "                    indexed_count = status.get(\"indexed_row_count\", 0)\n",
    "                    message = status.get(\"message\", \"\")\n",
    "                    \n",
    "                    # Get total row count at first check\n",
    "                    if first_check:\n",
    "                        total_rows = spec.get(\"num_rows\", 0)\n",
    "                        if total_rows > 0:\n",
    "                            print(f\"üìä Total number of rows to be indexed: {total_rows:,}\")\n",
    "                        first_check = False\n",
    "                    \n",
    "                    # Show progress\n",
    "                    elapsed = int(time.time() - start_time)\n",
    "                    rows_diff = indexed_count - previous_count\n",
    "                    speed = f\"{rows_diff:,} rows\" if rows_diff > 0 else \"Initializing\"\n",
    "                    \n",
    "                    print(f\"\\r‚è±Ô∏è  {elapsed//60}m {elapsed%60}s | \"\n",
    "                          f\"State: {state} | \"\n",
    "                          f\"Rows: {indexed_count:,} | \"\n",
    "                          f\"Speed: {speed}/30s | \"\n",
    "                          f\"Ready: {ready}\", end=\"\")\n",
    "                    \n",
    "                    previous_count = indexed_count\n",
    "                    \n",
    "                    # Success: ready is True and state is ONLINE or READY\n",
    "                    if ready == True and (\"ONLINE\" in state or state == \"READY\"):\n",
    "                      print(f\"\\n\\n‚úÖ Index is ready!\")\n",
    "                      print(f\"üìä Total indexed rows: {indexed_count:,}\")\n",
    "                      print(f\"‚è±Ô∏è  Total time: {elapsed//60}m {elapsed%60}s\")\n",
    "                      print(f\"üìã Final state: {state}\")\n",
    "                      return True\n",
    "                \n",
    "                    # Error\n",
    "                    if state in [\"FAILED\", \"ERROR\"]:\n",
    "                      print(f\"\\n\\n‚ùå Index creation failed!\")\n",
    "                      print(f\"Error state: {state}\")\n",
    "                      return False\n",
    "                \n",
    "                    # Timeout\n",
    "                    if elapsed > timeout_seconds:\n",
    "                      print(f\"\\n\\n‚è∞ Timed out after {timeout_minutes} minutes\")\n",
    "                      print(f\"Final state: {state}, Ready: {ready}\")\n",
    "                      return False\n",
    "                        \n",
    "                else:\n",
    "                    print(f\"\\n‚ö†Ô∏è  Status check error: {response.status_code}\")\n",
    "                    print(response.text)\n",
    "                \n",
    "                time.sleep(30)  # Check every 30 seconds\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\n‚ö†Ô∏è  Exception occurred: {e}\")\n",
    "                time.sleep(30)\n",
    "        \n",
    "        print(f\"\\n\\n‚è∞ Timed out after {timeout_minutes} minutes\")\n",
    "        return False\n",
    "    \n",
    "    # Start monitoring the index\n",
    "    success = monitor_index_status(index_name, timeout_minutes=60)\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\nüéâ Vector search index is ready!\")\n",
    "        \n",
    "        # Show final index info\n",
    "        final_url = f\"{host}/api/2.0/vector-search/indexes/{index_name}\"\n",
    "        final_response = requests.get(final_url, headers=headers)\n",
    "        if final_response.status_code == 200:\n",
    "            final_data = final_response.json()\n",
    "            print(f\"\\nüìã Index details:\")\n",
    "            print(f\"  - Name: {final_data.get('name')}\")\n",
    "            print(f\"  - Endpoint: {final_data.get('endpoint_name')}\")\n",
    "            print(f\"  - Status: {final_data.get('status', {}).get('detailed_state')}\")\n",
    "            print(f\"  - Rows: {final_data.get('status', {}).get('indexed_row_count', 0):,}\")\n",
    "    else:\n",
    "        print(\"\\nüòû Index creation did not complete successfully\")\n",
    "        \n",
    "elif response.status_code == 409:\n",
    "    print(\"‚ö†Ô∏è  Index already exists\")\n",
    "    print(\"You can delete and recreate it if necessary\")\n",
    "else:\n",
    "    print(f\"‚ùå Index creation error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1cb67d01-06b6-456d-9982-51c9cf3b808f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6494846239111437,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "00_Data preparation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
